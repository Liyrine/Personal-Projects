{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PHYS247_CreditCardFraud.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv2d3ro6nG9q"
      },
      "source": [
        "#Credit Card Fraud Detection\r\n",
        "###by Daniel Pham"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNJB0Na8bsl1"
      },
      "source": [
        "##README\r\n",
        "\r\n",
        "When running this .ipynb file on google collab, you **MAY** have to restart the runtime in order to use the imblearn library.\r\n",
        "\r\n",
        "If this is not being ran in any other IDE, make sure the imblearn library is installed in order for this code to be properly runned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_l26cuzIYOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd7332b-0572-4273-95d0-4d8065755225"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "\r\n",
        "!pip install -U imbalanced-learn\r\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix7ji4hebJth"
      },
      "source": [
        "The credit card fraud problem has given us known labels so I will look to do a supervised technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpTf-i09b9Kk"
      },
      "source": [
        "Since the output is binary in nature (fraud or not fraud), I decided that I will use **logistic regression** as my method for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO_ZEu3QyqPE"
      },
      "source": [
        "We then can take a look at the weights to see what are the main features that contribute to fraud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L6zar88w3sq"
      },
      "source": [
        "#Exploring the problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqeJIzIeMGZ_"
      },
      "source": [
        "#if uploading the CSV to google collab, it takes a while for it to be fully uploaded so please wait\r\n",
        "df = pd.read_csv(\"creditcard.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ZziARoJ7hjsX",
        "outputId": "5e50b4da-cad8-4726-f96b-493c0c18103c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT60J1FZdjGk",
        "outputId": "f07f1578-b5d0-4a91-b25f-e18259077707"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "9xKUqDnAu4e_",
        "outputId": "073325e9-b8aa-474a-a88b-14d25734a418"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxRrbb5XvBqH"
      },
      "source": [
        "Since this problem is about credit card fraud, there is usually a large class imbalance, so let's take a look at how poor is the class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPUTSg3-lGqQ",
        "outputId": "e2da7d5e-58ea-4444-fdf8-c090282ddcb6"
      },
      "source": [
        "class_count = pd.value_counts(df['Class'])\r\n",
        "print(class_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_U0qYIDtHO9"
      },
      "source": [
        "As shown, there is a huge class imbalance. Only 492 cases of fraud out of over 280,000 samples!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAUgcbgjyT6n"
      },
      "source": [
        "The algorithm may not be trained properly with too few samples of the minority class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qanWHeRexAe_"
      },
      "source": [
        "To solve this class imbalance, I will  oversample the miniority class (fraud) by **SMOTE** instead of undersampling the majority class (not fraud)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp7CB0AYJk3Y"
      },
      "source": [
        "Furthermore, this data is already cleaned up for us by the providers. All the features except for a couple are converted into PCA values. The features that were not converted into PCA values may need to normalized but we'll see."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUswNEADvAvX"
      },
      "source": [
        "#Creating Training and Test Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg0WcZVfOCiC"
      },
      "source": [
        "To properly train a logistic regression model, we will first need to make 2 separate sets from the data: a training set to train the model and a test set to test how accurate the good the trained model is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D0C19V-4Uc4"
      },
      "source": [
        "The training set will contain 80% of the data while the test set will contain the rest (20% of the data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNgU6ePO36Q2",
        "outputId": "f49d3f9b-cffc-4624-9ce6-24e0ee6ed82e"
      },
      "source": [
        "training_set, test_set = train_test_split(df, test_size = 0.2)\r\n",
        "\r\n",
        "#checking if it's done correctly\r\n",
        "\r\n",
        "training_set.info()\r\n",
        "test_set.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 227845 entries, 228044 to 158499\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    227845 non-null  float64\n",
            " 1   V1      227845 non-null  float64\n",
            " 2   V2      227845 non-null  float64\n",
            " 3   V3      227845 non-null  float64\n",
            " 4   V4      227845 non-null  float64\n",
            " 5   V5      227845 non-null  float64\n",
            " 6   V6      227845 non-null  float64\n",
            " 7   V7      227845 non-null  float64\n",
            " 8   V8      227845 non-null  float64\n",
            " 9   V9      227845 non-null  float64\n",
            " 10  V10     227845 non-null  float64\n",
            " 11  V11     227845 non-null  float64\n",
            " 12  V12     227845 non-null  float64\n",
            " 13  V13     227845 non-null  float64\n",
            " 14  V14     227845 non-null  float64\n",
            " 15  V15     227845 non-null  float64\n",
            " 16  V16     227845 non-null  float64\n",
            " 17  V17     227845 non-null  float64\n",
            " 18  V18     227845 non-null  float64\n",
            " 19  V19     227845 non-null  float64\n",
            " 20  V20     227845 non-null  float64\n",
            " 21  V21     227845 non-null  float64\n",
            " 22  V22     227845 non-null  float64\n",
            " 23  V23     227845 non-null  float64\n",
            " 24  V24     227845 non-null  float64\n",
            " 25  V25     227845 non-null  float64\n",
            " 26  V26     227845 non-null  float64\n",
            " 27  V27     227845 non-null  float64\n",
            " 28  V28     227845 non-null  float64\n",
            " 29  Amount  227845 non-null  float64\n",
            " 30  Class   227845 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 55.6 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 56962 entries, 236943 to 185161\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Time    56962 non-null  float64\n",
            " 1   V1      56962 non-null  float64\n",
            " 2   V2      56962 non-null  float64\n",
            " 3   V3      56962 non-null  float64\n",
            " 4   V4      56962 non-null  float64\n",
            " 5   V5      56962 non-null  float64\n",
            " 6   V6      56962 non-null  float64\n",
            " 7   V7      56962 non-null  float64\n",
            " 8   V8      56962 non-null  float64\n",
            " 9   V9      56962 non-null  float64\n",
            " 10  V10     56962 non-null  float64\n",
            " 11  V11     56962 non-null  float64\n",
            " 12  V12     56962 non-null  float64\n",
            " 13  V13     56962 non-null  float64\n",
            " 14  V14     56962 non-null  float64\n",
            " 15  V15     56962 non-null  float64\n",
            " 16  V16     56962 non-null  float64\n",
            " 17  V17     56962 non-null  float64\n",
            " 18  V18     56962 non-null  float64\n",
            " 19  V19     56962 non-null  float64\n",
            " 20  V20     56962 non-null  float64\n",
            " 21  V21     56962 non-null  float64\n",
            " 22  V22     56962 non-null  float64\n",
            " 23  V23     56962 non-null  float64\n",
            " 24  V24     56962 non-null  float64\n",
            " 25  V25     56962 non-null  float64\n",
            " 26  V26     56962 non-null  float64\n",
            " 27  V27     56962 non-null  float64\n",
            " 28  V28     56962 non-null  float64\n",
            " 29  Amount  56962 non-null  float64\n",
            " 30  Class   56962 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 13.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyeNqiSA5dF3"
      },
      "source": [
        "Creating a variable that contains just *labels* for the samples for both training and test set to use for scikit-learn's library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKv0vJXt4KB3",
        "outputId": "d82fee3f-4cf9-4e0a-9ecf-e41f18f31901"
      },
      "source": [
        "training_labels = training_set['Class']\r\n",
        "test_labels = test_set['Class']\r\n",
        "\r\n",
        "#checking if it's done correctly\r\n",
        "training_labels.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "228044    0\n",
              "13108     0\n",
              "258199    0\n",
              "83554     0\n",
              "46084     0\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuaHGPit57zs"
      },
      "source": [
        "Dropping the 'Class' column to create a variable of just *features* for both training and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "Y9da3jko5nvo",
        "outputId": "61e3b725-f2c0-4547-916d-8af9705dc882"
      },
      "source": [
        "training_features = training_set.drop(['Class'], axis = 1)\r\n",
        "test_features = test_set.drop(['Class'], axis = 1)\r\n",
        "\r\n",
        "#checking if it's done correctly\r\n",
        "training_features.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>228044</th>\n",
              "      <td>145335.0</td>\n",
              "      <td>2.065967</td>\n",
              "      <td>-0.327213</td>\n",
              "      <td>-2.221817</td>\n",
              "      <td>-0.713805</td>\n",
              "      <td>0.435340</td>\n",
              "      <td>-1.028121</td>\n",
              "      <td>0.451890</td>\n",
              "      <td>-0.285918</td>\n",
              "      <td>0.407632</td>\n",
              "      <td>0.016286</td>\n",
              "      <td>0.858679</td>\n",
              "      <td>0.489616</td>\n",
              "      <td>-1.233011</td>\n",
              "      <td>0.975564</td>\n",
              "      <td>-0.612040</td>\n",
              "      <td>-0.618106</td>\n",
              "      <td>-0.110769</td>\n",
              "      <td>-0.281928</td>\n",
              "      <td>0.741601</td>\n",
              "      <td>-0.197287</td>\n",
              "      <td>0.142837</td>\n",
              "      <td>0.469987</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.792088</td>\n",
              "      <td>0.240474</td>\n",
              "      <td>1.027339</td>\n",
              "      <td>-0.156490</td>\n",
              "      <td>-0.093711</td>\n",
              "      <td>27.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13108</th>\n",
              "      <td>23003.0</td>\n",
              "      <td>-0.250748</td>\n",
              "      <td>0.228252</td>\n",
              "      <td>1.997959</td>\n",
              "      <td>-0.668625</td>\n",
              "      <td>-0.653781</td>\n",
              "      <td>-0.404783</td>\n",
              "      <td>-0.247943</td>\n",
              "      <td>0.087898</td>\n",
              "      <td>2.572726</td>\n",
              "      <td>-1.660099</td>\n",
              "      <td>0.791595</td>\n",
              "      <td>-2.089710</td>\n",
              "      <td>1.127353</td>\n",
              "      <td>1.387759</td>\n",
              "      <td>0.860167</td>\n",
              "      <td>-1.212940</td>\n",
              "      <td>1.226730</td>\n",
              "      <td>0.228861</td>\n",
              "      <td>0.645060</td>\n",
              "      <td>-0.071120</td>\n",
              "      <td>0.050256</td>\n",
              "      <td>0.625550</td>\n",
              "      <td>0.084838</td>\n",
              "      <td>0.355037</td>\n",
              "      <td>-0.857608</td>\n",
              "      <td>-0.769203</td>\n",
              "      <td>0.269768</td>\n",
              "      <td>0.205272</td>\n",
              "      <td>11.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258199</th>\n",
              "      <td>158539.0</td>\n",
              "      <td>-1.121313</td>\n",
              "      <td>0.771984</td>\n",
              "      <td>1.068908</td>\n",
              "      <td>-1.380343</td>\n",
              "      <td>0.517473</td>\n",
              "      <td>0.200858</td>\n",
              "      <td>0.500902</td>\n",
              "      <td>0.033177</td>\n",
              "      <td>1.298020</td>\n",
              "      <td>0.070078</td>\n",
              "      <td>-1.622049</td>\n",
              "      <td>-0.870944</td>\n",
              "      <td>-1.109992</td>\n",
              "      <td>-0.394997</td>\n",
              "      <td>0.651399</td>\n",
              "      <td>0.288610</td>\n",
              "      <td>-0.863619</td>\n",
              "      <td>0.131083</td>\n",
              "      <td>0.090543</td>\n",
              "      <td>0.198547</td>\n",
              "      <td>-0.380745</td>\n",
              "      <td>-0.619611</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>-0.042411</td>\n",
              "      <td>-0.106341</td>\n",
              "      <td>-0.264659</td>\n",
              "      <td>0.317570</td>\n",
              "      <td>0.066396</td>\n",
              "      <td>7.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83554</th>\n",
              "      <td>59914.0</td>\n",
              "      <td>-1.029989</td>\n",
              "      <td>1.269654</td>\n",
              "      <td>2.026286</td>\n",
              "      <td>0.984254</td>\n",
              "      <td>0.853755</td>\n",
              "      <td>0.189979</td>\n",
              "      <td>1.372185</td>\n",
              "      <td>-0.798930</td>\n",
              "      <td>-0.061175</td>\n",
              "      <td>2.021282</td>\n",
              "      <td>1.551693</td>\n",
              "      <td>-0.458205</td>\n",
              "      <td>-1.458916</td>\n",
              "      <td>-0.545649</td>\n",
              "      <td>-0.371239</td>\n",
              "      <td>0.431947</td>\n",
              "      <td>-1.267890</td>\n",
              "      <td>-0.298401</td>\n",
              "      <td>-1.891030</td>\n",
              "      <td>-0.012271</td>\n",
              "      <td>-0.042010</td>\n",
              "      <td>0.161717</td>\n",
              "      <td>-0.169810</td>\n",
              "      <td>0.141905</td>\n",
              "      <td>-0.391466</td>\n",
              "      <td>-0.469039</td>\n",
              "      <td>-1.348529</td>\n",
              "      <td>-0.787572</td>\n",
              "      <td>8.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46084</th>\n",
              "      <td>42633.0</td>\n",
              "      <td>-0.335568</td>\n",
              "      <td>0.982971</td>\n",
              "      <td>1.595383</td>\n",
              "      <td>1.034390</td>\n",
              "      <td>0.292466</td>\n",
              "      <td>0.067714</td>\n",
              "      <td>1.041377</td>\n",
              "      <td>-0.185117</td>\n",
              "      <td>-1.021620</td>\n",
              "      <td>0.269348</td>\n",
              "      <td>1.988393</td>\n",
              "      <td>0.981614</td>\n",
              "      <td>0.405207</td>\n",
              "      <td>0.301178</td>\n",
              "      <td>0.742268</td>\n",
              "      <td>-0.538149</td>\n",
              "      <td>-0.102792</td>\n",
              "      <td>-0.535909</td>\n",
              "      <td>0.784026</td>\n",
              "      <td>0.109466</td>\n",
              "      <td>-0.333262</td>\n",
              "      <td>-0.862850</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>0.156859</td>\n",
              "      <td>-0.410384</td>\n",
              "      <td>-0.765186</td>\n",
              "      <td>-0.207621</td>\n",
              "      <td>-0.193970</td>\n",
              "      <td>52.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2  ...       V27       V28  Amount\n",
              "228044  145335.0  2.065967 -0.327213  ... -0.156490 -0.093711   27.00\n",
              "13108    23003.0 -0.250748  0.228252  ...  0.269768  0.205272   11.85\n",
              "258199  158539.0 -1.121313  0.771984  ...  0.317570  0.066396    7.68\n",
              "83554    59914.0 -1.029989  1.269654  ... -1.348529 -0.787572    8.13\n",
              "46084    42633.0 -0.335568  0.982971  ... -0.207621 -0.193970   52.00\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRxOqPDqvd7j"
      },
      "source": [
        "We have 4 new variables. Now we can refer to the features and labels of the training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNxFcCAZ0tXl"
      },
      "source": [
        "#Applying Scikit-learn's Logistic Regression **without** SMOTE sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gY5B-G953r1"
      },
      "source": [
        "First, we want to see how the logistic regression algorithm will fare without applying oversampling to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj-j1Rd9-9dA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644769c1-a43a-4fda-93fe-c5a3487b6021"
      },
      "source": [
        "#create the trained algorithm by using the training set\r\n",
        "logreg = LogisticRegression(max_iter=1000)\r\n",
        "logreg.fit(training_features, training_labels)\r\n",
        "\r\n",
        "#test the algorithm with the test set\r\n",
        "logreg_score = logreg.score(test_features, test_labels)\r\n",
        "print(\"Logistic regression accuracy without oversampling:\", logreg_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression accuracy without oversampling: 0.9991748885221726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB0OEUMZ6By6"
      },
      "source": [
        "Scikit-learn's library fitted the model to the dataset really well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exbB8oDM6sXd"
      },
      "source": [
        "Now I will cross-validate the model over 10-folds of sampling to see if it returns similar accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYN1m66D6d3d",
        "outputId": "8c9c066d-7814-4e8f-c1c6-b58e0baa5dcf"
      },
      "source": [
        "cv_scores = cross_val_score(logreg, training_features, training_labels, cv=10)\r\n",
        "\r\n",
        "print(\"Cross Validation Scores without oversampling: \\n\", cv_scores)\r\n",
        "\r\n",
        "cv_scores = pd.Series(cv_scores)\r\n",
        "print(\"Cross Validation Minimum:\", cv_scores.min())\r\n",
        "print(\"Cross Validation Mean:\", cv_scores.mean()) \r\n",
        "print(\"Cross Validation Max:\", cv_scores.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Scores without oversampling: \n",
            " [0.99938556 0.99921001 0.99868334 0.99916612 0.9992539  0.99916608\n",
            " 0.99916608 0.9990783  0.99920997 0.99920997]\n",
            "Cross Validation Minimum: 0.9986833443054641\n",
            "Cross Validation Mean: 0.9991529332034554\n",
            "Cross Validation Max: 0.9993855606758832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHbGJmUW81uB"
      },
      "source": [
        "Looking at the cross validation scores, our model overall is having similar accuracy scores as to our trained accuracy. But is it actually predicting the class that we are interested in (the samples that are fraud) correctly?\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFqll-83-Aix"
      },
      "source": [
        "It is time to look at the confusion matrix and F-scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kFufOBd9xaw",
        "outputId": "cb8dcec7-3b1a-4600-e335-27ce0ad34784"
      },
      "source": [
        "#having the trained model predict over the test set\r\n",
        "predictions = logreg.predict(test_features)\r\n",
        "\r\n",
        "#confusion matrix from comparing the predictions to the data's actual labels\r\n",
        "cm =  confusion_matrix(test_labels, predictions)\r\n",
        "\r\n",
        "print(\"Confusion matrix without oversampling: \\n\", cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix without oversampling: \n",
            " [[56839    18]\n",
            " [   29    76]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2thkUbp_oxK"
      },
      "source": [
        "To interpret this...\r\n",
        "\r\n",
        "**Upper Left Corner**: The amount of correctly classified by the model for non-fraudulent transactions.\r\n",
        "\r\n",
        "**Upper Right Corner**: The amount of incorrectly classified as fraudulent transactions, but the actual label is non-fraudulent.\r\n",
        "\r\n",
        "**Lower Left Corner**: The amount of incorrectly classified as non-fraudulent transactions, but the actual label is fraudulent.\r\n",
        "\r\n",
        "**Lower Right Corner**: The amount of correctly classified by the model for fraudulent transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThMKF2sBA-_k"
      },
      "source": [
        "From an eyeball glance of the confusion matrix, the model is predicting very well for the non-fraudulent transactions. But that is not what we're interested looking at."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7DzJLO0Briz"
      },
      "source": [
        "When taking a look at fraudulent cases for the confusion matrix, we are getting a rather unsatisfactory result as expected. The model is correctly predicting fraudulent cases at least 70% of the time. From an industry point of view, this model is most likely not good enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTuZhtJTCrte"
      },
      "source": [
        "To further reinforce the results, let's take a look at the classification report for the cunfusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j30w9CZN_ruw",
        "outputId": "8e125eda-fd2a-4f39-84a7-30467cdce7cc"
      },
      "source": [
        "report = classification_report(test_labels, predictions)\r\n",
        "\r\n",
        "print(\"Classification report without oversampling: \\n\", report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report without oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56857\n",
            "           1       0.81      0.72      0.76       105\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.90      0.86      0.88     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifH_zHM9OoXP"
      },
      "source": [
        "**Precision** refers to how what percentage of positive class identifications are actually correct while **recall** refers to what percentage of positive classes are identified correctly. And F1-score combines the precision and recall score together.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-63J1FWeDO_W"
      },
      "source": [
        "According to this, the precision and recall is excellent for the non-fraudulent cases and somewhat okay for the fraudulent cases. The F1-score seem to suggest that overall, the model did decent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpKaICFZEBd5"
      },
      "source": [
        "Let's do one last check to see how this model of no oversampling fares by the ROC curve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUnNf8YnQdC4"
      },
      "source": [
        "ROC curve is a performance measurement which tells how capable the model is at distinguishing different classes. It scores between 0.5 to 1.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6tXSiAUD_50",
        "outputId": "265c2a55-91e5-47d4-98bd-6d2325f8f0dd"
      },
      "source": [
        "auc_score = roc_auc_score(test_labels, predictions)\r\n",
        "\r\n",
        "print(\"AUC score without oversampling:\", auc_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score without oversampling: 0.8617464700497574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWnZ8aSHFgcG"
      },
      "source": [
        "This area-under-the-curve (AUC) score is rather good. This suggests that the model here can be used for credit card fraud detection, but that does not mean we cannot do better. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR3n3lDxJHKF"
      },
      "source": [
        "#Applying Scikit-learn's Logistic Regression **with** SMOTE sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mqvF2B1GkZJ"
      },
      "source": [
        "As mentioned earlier, this problem has a huge class imbalance and the model may not be trained properly due to this imbalance. Therefore, it is now time to implement SMOTE oversampling, and hopefully, the algorithm would improve."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gRm8G9hRS_t"
      },
      "source": [
        "We need to now create new variables for the **training** set using SMOTE.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z50L2zQIGi7Y"
      },
      "source": [
        "smote = SMOTE(random_state = 10, sampling_strategy = 1.0)\r\n",
        "training_features_smote, training_labels_smote = smote.fit_resample(training_features, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSxjrMOHX-Tm"
      },
      "source": [
        "Now we just need to repeat what we did earlier, except with new SMOTE training set variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7-HY8jPWlYE"
      },
      "source": [
        "Creating a logistic regression model with SMOTE variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnuQm4rLHtRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e10549-db58-4379-8964-70fefb3eeba6"
      },
      "source": [
        "logreg_smote = LogisticRegression(max_iter=1000)\r\n",
        "logreg_smote.fit(training_features_smote, training_labels_smote)\r\n",
        "\r\n",
        "logreg_score_smote = logreg_smote.score(test_features, test_labels)\r\n",
        "print(\"Logistic regression accuracy with oversampling:\", logreg_score_smote)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression accuracy with oversampling: 0.9825146588954039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWhtgZNg6sLV"
      },
      "source": [
        "We see here that the logistic regression model with SMOTE resulted in a slightly lower overall accuracy than the model without SMOTE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfLGeZHzeo-I"
      },
      "source": [
        "This might be due to the model sacrificing some accuracy to better predict the class that we are interested in due to it being oversampled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PNuaGkCXYN1",
        "outputId": "959eb442-ad0a-4160-c5a2-e39bdf0403bf"
      },
      "source": [
        "cv_scores_smote = cross_val_score(logreg_smote, training_features_smote, training_labels_smote, cv=10)\r\n",
        "\r\n",
        "print(\"Cross Validation Scores with oversampling: \\n\", cv_scores_smote)\r\n",
        "\r\n",
        "cv_scores_smote = pd.Series(cv_scores_smote)\r\n",
        "print(\"Cross Validation Minimum:\", cv_scores_smote.min())\r\n",
        "print(\"Cross Validation Mean:\", cv_scores_smote.mean()) \r\n",
        "print(\"Cross Validation Max:\", cv_scores_smote.max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross Validation Scores with oversampling: \n",
            " [0.97247868 0.95414578 0.97410534 0.9695331  0.96975292 0.97340192\n",
            " 0.95284782 0.97164274 0.9734453  0.95495812]\n",
            "Cross Validation Minimum: 0.9528478160515267\n",
            "Cross Validation Mean: 0.9666311722807948\n",
            "Cross Validation Max: 0.9741053372021454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGwmVEOoiJgt"
      },
      "source": [
        "Like before, the cross validation results are producing similar accuracy as to our trained SMOTE model's accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_ufGFbriplg"
      },
      "source": [
        "Now let's take a look if the model is actually accurately predicting the fraudulent cases correctly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cobI_vacWjii",
        "outputId": "705b1cf0-4ba3-4435-db4a-dbd0f7a46f06"
      },
      "source": [
        "predictions_smote = logreg_smote.predict(test_features)\r\n",
        "\r\n",
        "cm_smote =  confusion_matrix(test_labels, predictions_smote)\r\n",
        "\r\n",
        "print(\"Confusion matrix with oversampling: \\n\", cm_smote)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix with oversampling: \n",
            " [[55869   988]\n",
            " [    8    97]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYgzCuEYi9g9"
      },
      "source": [
        "As a reminder...\r\n",
        "\r\n",
        "**Upper Left Corner**: The amount of correctly classified by the model for non-fraudulent transactions.\r\n",
        "\r\n",
        "**Upper Right Corner**: The amount of incorrectly classified as fraudulent transactions, but the actual label is non-fraudulent.\r\n",
        "\r\n",
        "**Lower Left Corner**: The amount of incorrectly classified as non-fraudulent transactions, but the actual label is fraudulent.\r\n",
        "\r\n",
        "**Lower Right Corner**: The amount of correctly classified by the model for fraudulent transactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgf5KqyLjUE-"
      },
      "source": [
        "As a result of the model being trained through SMOTE, the model has at least a 90% accuracy in predicting in the class that we are interested in! That is a big improvement compared to previous 70% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XCZnvSMkEE-"
      },
      "source": [
        "However, we do see that it is predicting more non-fraudulent cases as fraudulent. But, that is fine since it is better to be safe than sorry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HMlrLQPkoyR"
      },
      "source": [
        "Credit card companies can better protect their consumers and get people to verify their transactions if the algorithm think it is fraudulent case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yU2SJeQYXK"
      },
      "source": [
        "Now let's see what the classification report says."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zPuFDNyZSOh",
        "outputId": "281d7e19-8cbb-4ae9-de16-27a6b11d7e18"
      },
      "source": [
        "report_smote = classification_report(test_labels, predictions_smote)\r\n",
        "\r\n",
        "print(\"Classification report with oversampling: \\n\", report_smote)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report without oversampling: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     56857\n",
            "           1       0.09      0.92      0.16       105\n",
            "\n",
            "    accuracy                           0.98     56962\n",
            "   macro avg       0.54      0.95      0.58     56962\n",
            "weighted avg       1.00      0.98      0.99     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yOAkROjQcCc"
      },
      "source": [
        "As another a reminder...\r\n",
        "\r\n",
        "**Precision** refers to how what percentage of positive class identifications are actually correct while **recall** refers to what percentage of positive classes are identified correctly. And F1-score combines the precision and recall score together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIssD1l4QnRn"
      },
      "source": [
        "We see here that the results further reinforce what I was saying earlier. The low score in precision resulted from the model predicting more non-fraudulent cases as fraudulent. But in exchange, the model is predicting fraudulent cases much more accurately. The F-score may look very poor, but in actuality, this is a much better model than the one without oversampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlcAvRhZR3Wy"
      },
      "source": [
        "Lastly, let's see what the ROC curve suggests about the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aep7ObXiZlhW",
        "outputId": "cc19aa75-a086-4d5e-da13-cd4c196437d8"
      },
      "source": [
        "auc_score_smote = roc_auc_score(test_labels, predictions_smote)\r\n",
        "\r\n",
        "print(\"AUC score with oversampling:\", auc_score_smote)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC score without oversampling: 0.953216297863395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INdtY3T6uGKS"
      },
      "source": [
        "This AUC score is quite excellent and would be great one to use in the industry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDv34QNoFPUe"
      },
      "source": [
        "When compared to the previous score, this score suggests that this model, which was trained through oversampling the minority class, is the better one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B90x6S1blrex"
      },
      "source": [
        "#Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us4WNwPMSglA"
      },
      "source": [
        "In conclusion, logistic regression is a great model to use for credit card detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqsBHxdeSssk"
      },
      "source": [
        "Since there was a huge class imbalance, training the model with SMOTE oversampling yielded a much better algorithm for the class that we are interested in than training the model without it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zft9PsKTY2b"
      },
      "source": [
        "Now let's see which features in particular heavily influenced if a transaction was fraudulent or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GEO6r3ooVy8",
        "outputId": "06147b69-0b59-4c25-ad4e-ba8dbf8ee082"
      },
      "source": [
        "#this contains all the weights in algorithm\r\n",
        "weights = logreg_smote.coef_\r\n",
        "\r\n",
        "#this contains all the feature names\r\n",
        "features = df.columns.values\r\n",
        "\r\n",
        "#creates a dictionary of the features and their associated weights\r\n",
        "weights_dict = {}\r\n",
        "for weight, feat in zip(weights[0,:], features):\r\n",
        "    weights_dict[feat] = weight\r\n",
        "\r\n",
        "#prints all key value pairs in dictionary\r\n",
        "for element in weights_dict.items():\r\n",
        "  print(element)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Time', -3.757874976432943e-05)\n",
            "('V1', 0.15019753375998096)\n",
            "('V2', -0.2489840494760921)\n",
            "('V3', -0.8587742651232082)\n",
            "('V4', 0.8637960973558975)\n",
            "('V5', 0.26399804892451945)\n",
            "('V6', -0.3029587023427311)\n",
            "('V7', -0.23103062793153795)\n",
            "('V8', -0.4395015697357681)\n",
            "('V9', -0.5360104612444051)\n",
            "('V10', -0.6424805605493271)\n",
            "('V11', 0.2349376690388481)\n",
            "('V12', -0.8696767603767634)\n",
            "('V13', -0.44404124544872386)\n",
            "('V14', -1.4416911904021594)\n",
            "('V15', -0.2613064095415009)\n",
            "('V16', -0.6275713551943845)\n",
            "('V17', -1.0287285616573794)\n",
            "('V18', -0.12192251237622763)\n",
            "('V19', 0.2052061882717862)\n",
            "('V20', 0.03372111805303771)\n",
            "('V21', 0.11090756685767993)\n",
            "('V22', 0.36430690113643127)\n",
            "('V23', 0.06889949398808184)\n",
            "('V24', 0.08887837331977193)\n",
            "('V25', -0.2228668997492212)\n",
            "('V26', -0.06125643451590009)\n",
            "('V27', 0.07206251068071699)\n",
            "('V28', 0.0333622415501257)\n",
            "('Amount', -0.0004798187593282112)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox3uoQsoTn3w"
      },
      "source": [
        "Since this is logistic regression, negative weights would make the model incline to output a 0 (aka the class we are NOT interested in) while positive weights would make the model incline to output a 1 (aka the class we are interested in)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1UYCHwTUGDT"
      },
      "source": [
        "The features \"Time\", \"V14\", and \"V17\" seem to be the most significant features to influencing non-fraudulent cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KcZIukTUiS3"
      },
      "source": [
        "The features \"V4\", \"V19\", and \"V22\" seem to be the most significant features to influencing fraudulent cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-crm4YvvUEzh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}